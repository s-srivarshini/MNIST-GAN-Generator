{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0773dbbe-aa18-4847-9571-25eb48c59315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b28a0564-ca21-4c2c-90ef-36105a216c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [200/600], Loss_D: 0.09874388575553894, Loss_G: 7.03685188293457\n",
      "Epoch [1/100], Step [400/600], Loss_D: 0.13508620858192444, Loss_G: 5.099188804626465\n",
      "Epoch [1/100], Step [600/600], Loss_D: 0.4734697937965393, Loss_G: 4.120473384857178\n",
      "Epoch [2/100], Step [200/600], Loss_D: 0.4999423623085022, Loss_G: 2.0276451110839844\n",
      "Epoch [2/100], Step [400/600], Loss_D: 0.8440132141113281, Loss_G: 1.513079285621643\n",
      "Epoch [2/100], Step [600/600], Loss_D: 1.6606357097625732, Loss_G: 1.2800430059432983\n",
      "Epoch [3/100], Step [200/600], Loss_D: 0.3642454147338867, Loss_G: 3.244110107421875\n",
      "Epoch [3/100], Step [400/600], Loss_D: 0.9636448621749878, Loss_G: 1.4988113641738892\n",
      "Epoch [3/100], Step [600/600], Loss_D: 2.0083513259887695, Loss_G: 4.388504981994629\n",
      "Epoch [4/100], Step [200/600], Loss_D: 0.12781336903572083, Loss_G: 3.739996910095215\n",
      "Epoch [4/100], Step [400/600], Loss_D: 2.888962745666504, Loss_G: 1.0993353128433228\n",
      "Epoch [4/100], Step [600/600], Loss_D: 1.4035427570343018, Loss_G: 4.930037498474121\n",
      "Epoch [5/100], Step [200/600], Loss_D: 0.30831050872802734, Loss_G: 8.318856239318848\n",
      "Epoch [5/100], Step [400/600], Loss_D: 0.3796112537384033, Loss_G: 2.675377130508423\n",
      "Epoch [5/100], Step [600/600], Loss_D: 1.5324784517288208, Loss_G: 3.3987743854522705\n",
      "Epoch [6/100], Step [200/600], Loss_D: 0.14108505845069885, Loss_G: 3.7502381801605225\n",
      "Epoch [6/100], Step [400/600], Loss_D: 0.967993974685669, Loss_G: 1.8369375467300415\n",
      "Epoch [6/100], Step [600/600], Loss_D: 2.353283405303955, Loss_G: 2.286607265472412\n",
      "Epoch [7/100], Step [200/600], Loss_D: 1.423278570175171, Loss_G: 1.397066593170166\n",
      "Epoch [7/100], Step [400/600], Loss_D: 0.19547513127326965, Loss_G: 5.362880229949951\n",
      "Epoch [7/100], Step [600/600], Loss_D: 0.816243588924408, Loss_G: 2.5505919456481934\n",
      "Epoch [8/100], Step [200/600], Loss_D: 1.196436882019043, Loss_G: 2.183722972869873\n",
      "Epoch [8/100], Step [400/600], Loss_D: 0.792595386505127, Loss_G: 2.192692756652832\n",
      "Epoch [8/100], Step [600/600], Loss_D: 1.6429100036621094, Loss_G: 1.0440689325332642\n",
      "Epoch [9/100], Step [200/600], Loss_D: 0.9612321853637695, Loss_G: 1.136046290397644\n",
      "Epoch [9/100], Step [400/600], Loss_D: 1.6585333347320557, Loss_G: 0.9678840637207031\n",
      "Epoch [9/100], Step [600/600], Loss_D: 0.4744582176208496, Loss_G: 2.2810890674591064\n",
      "Epoch [10/100], Step [200/600], Loss_D: 1.0380544662475586, Loss_G: 1.0802308320999146\n",
      "Epoch [10/100], Step [400/600], Loss_D: 0.8944703936576843, Loss_G: 2.209482192993164\n",
      "Epoch [10/100], Step [600/600], Loss_D: 1.603129267692566, Loss_G: 0.8948015570640564\n",
      "Epoch [11/100], Step [200/600], Loss_D: 1.083221673965454, Loss_G: 1.3159469366073608\n",
      "Epoch [11/100], Step [400/600], Loss_D: 0.8568105101585388, Loss_G: 2.0807530879974365\n",
      "Epoch [11/100], Step [600/600], Loss_D: 1.4164679050445557, Loss_G: 1.8289053440093994\n",
      "Epoch [12/100], Step [200/600], Loss_D: 0.6338829398155212, Loss_G: 2.218379497528076\n",
      "Epoch [12/100], Step [400/600], Loss_D: 0.41456636786460876, Loss_G: 4.679783344268799\n",
      "Epoch [12/100], Step [600/600], Loss_D: 0.6162751317024231, Loss_G: 2.4058432579040527\n",
      "Epoch [13/100], Step [200/600], Loss_D: 0.9881864786148071, Loss_G: 4.8683180809021\n",
      "Epoch [13/100], Step [400/600], Loss_D: 0.22495612502098083, Loss_G: 3.2185046672821045\n",
      "Epoch [13/100], Step [600/600], Loss_D: 0.7936826348304749, Loss_G: 2.7119107246398926\n",
      "Epoch [14/100], Step [200/600], Loss_D: 0.7508046627044678, Loss_G: 2.6394920349121094\n",
      "Epoch [14/100], Step [400/600], Loss_D: 0.9396413564682007, Loss_G: 1.8235127925872803\n",
      "Epoch [14/100], Step [600/600], Loss_D: 0.6803121566772461, Loss_G: 2.5203802585601807\n",
      "Epoch [15/100], Step [200/600], Loss_D: 0.5208708047866821, Loss_G: 2.3522427082061768\n",
      "Epoch [15/100], Step [400/600], Loss_D: 0.7793608903884888, Loss_G: 2.975705146789551\n",
      "Epoch [15/100], Step [600/600], Loss_D: 0.7704144716262817, Loss_G: 1.9426946640014648\n",
      "Epoch [16/100], Step [200/600], Loss_D: 0.8352430462837219, Loss_G: 1.5921361446380615\n",
      "Epoch [16/100], Step [400/600], Loss_D: 0.553471565246582, Loss_G: 1.9993247985839844\n",
      "Epoch [16/100], Step [600/600], Loss_D: 0.7659629583358765, Loss_G: 1.8817434310913086\n",
      "Epoch [17/100], Step [200/600], Loss_D: 0.4890158176422119, Loss_G: 2.39180850982666\n",
      "Epoch [17/100], Step [400/600], Loss_D: 0.5730385780334473, Loss_G: 2.3664262294769287\n",
      "Epoch [17/100], Step [600/600], Loss_D: 0.6340121626853943, Loss_G: 2.096188545227051\n",
      "Epoch [18/100], Step [200/600], Loss_D: 0.6677768230438232, Loss_G: 2.422154426574707\n",
      "Epoch [18/100], Step [400/600], Loss_D: 0.8838837146759033, Loss_G: 3.354628324508667\n",
      "Epoch [18/100], Step [600/600], Loss_D: 0.4405447542667389, Loss_G: 3.340303897857666\n",
      "Epoch [19/100], Step [200/600], Loss_D: 0.8873579502105713, Loss_G: 2.4188194274902344\n",
      "Epoch [19/100], Step [400/600], Loss_D: 0.9521752595901489, Loss_G: 2.4426705837249756\n",
      "Epoch [19/100], Step [600/600], Loss_D: 0.4312646985054016, Loss_G: 2.326578378677368\n",
      "Epoch [20/100], Step [200/600], Loss_D: 1.0145659446716309, Loss_G: 1.9532835483551025\n",
      "Epoch [20/100], Step [400/600], Loss_D: 0.7411545515060425, Loss_G: 2.5604028701782227\n",
      "Epoch [20/100], Step [600/600], Loss_D: 0.9806814193725586, Loss_G: 2.5515730381011963\n",
      "Epoch [21/100], Step [200/600], Loss_D: 0.5784759521484375, Loss_G: 2.070868730545044\n",
      "Epoch [21/100], Step [400/600], Loss_D: 0.49096953868865967, Loss_G: 2.170809268951416\n",
      "Epoch [21/100], Step [600/600], Loss_D: 0.4065621495246887, Loss_G: 5.040590286254883\n",
      "Epoch [22/100], Step [200/600], Loss_D: 0.42931658029556274, Loss_G: 4.544772624969482\n",
      "Epoch [22/100], Step [400/600], Loss_D: 0.5697056651115417, Loss_G: 3.7406628131866455\n",
      "Epoch [22/100], Step [600/600], Loss_D: 0.8347762823104858, Loss_G: 2.2768425941467285\n",
      "Epoch [23/100], Step [200/600], Loss_D: 1.099764108657837, Loss_G: 3.274115800857544\n",
      "Epoch [23/100], Step [400/600], Loss_D: 0.6328850388526917, Loss_G: 1.884429931640625\n",
      "Epoch [23/100], Step [600/600], Loss_D: 0.5088262557983398, Loss_G: 3.050736427307129\n",
      "Epoch [24/100], Step [200/600], Loss_D: 0.3605184555053711, Loss_G: 3.254284381866455\n",
      "Epoch [24/100], Step [400/600], Loss_D: 0.5894602537155151, Loss_G: 4.533253192901611\n",
      "Epoch [24/100], Step [600/600], Loss_D: 0.6690956354141235, Loss_G: 2.486356735229492\n",
      "Epoch [25/100], Step [200/600], Loss_D: 0.6148574352264404, Loss_G: 2.4350972175598145\n",
      "Epoch [25/100], Step [400/600], Loss_D: 0.29932355880737305, Loss_G: 3.3074822425842285\n",
      "Epoch [25/100], Step [600/600], Loss_D: 1.0258256196975708, Loss_G: 2.6338512897491455\n",
      "Epoch [26/100], Step [200/600], Loss_D: 0.8678328394889832, Loss_G: 2.6174089908599854\n",
      "Epoch [26/100], Step [400/600], Loss_D: 1.1189018487930298, Loss_G: 2.6032426357269287\n",
      "Epoch [26/100], Step [600/600], Loss_D: 0.9574384689331055, Loss_G: 1.910521388053894\n",
      "Epoch [27/100], Step [200/600], Loss_D: 0.7690078616142273, Loss_G: 2.768414258956909\n",
      "Epoch [27/100], Step [400/600], Loss_D: 0.49050670862197876, Loss_G: 3.158193349838257\n",
      "Epoch [27/100], Step [600/600], Loss_D: 0.8578247427940369, Loss_G: 2.713564395904541\n",
      "Epoch [28/100], Step [200/600], Loss_D: 0.7087187767028809, Loss_G: 2.05088210105896\n",
      "Epoch [28/100], Step [400/600], Loss_D: 0.42205187678337097, Loss_G: 2.897939443588257\n",
      "Epoch [28/100], Step [600/600], Loss_D: 0.552665114402771, Loss_G: 2.4243621826171875\n",
      "Epoch [29/100], Step [200/600], Loss_D: 0.5358331203460693, Loss_G: 3.8418331146240234\n",
      "Epoch [29/100], Step [400/600], Loss_D: 0.6251075267791748, Loss_G: 2.383498430252075\n",
      "Epoch [29/100], Step [600/600], Loss_D: 0.48967716097831726, Loss_G: 2.273207664489746\n",
      "Epoch [30/100], Step [200/600], Loss_D: 0.7219225168228149, Loss_G: 2.467280626296997\n",
      "Epoch [30/100], Step [400/600], Loss_D: 0.7845306992530823, Loss_G: 2.9342455863952637\n",
      "Epoch [30/100], Step [600/600], Loss_D: 0.7644550204277039, Loss_G: 3.357609272003174\n",
      "Epoch [31/100], Step [200/600], Loss_D: 0.5607959032058716, Loss_G: 3.379909038543701\n",
      "Epoch [31/100], Step [400/600], Loss_D: 0.8290272951126099, Loss_G: 1.763560175895691\n",
      "Epoch [31/100], Step [600/600], Loss_D: 0.867894172668457, Loss_G: 2.011066198348999\n",
      "Epoch [32/100], Step [200/600], Loss_D: 0.49022558331489563, Loss_G: 2.5914087295532227\n",
      "Epoch [32/100], Step [400/600], Loss_D: 0.8172620534896851, Loss_G: 2.516038179397583\n",
      "Epoch [32/100], Step [600/600], Loss_D: 0.6216424703598022, Loss_G: 2.102715253829956\n",
      "Epoch [33/100], Step [200/600], Loss_D: 0.5113813877105713, Loss_G: 2.9096336364746094\n",
      "Epoch [33/100], Step [400/600], Loss_D: 0.6359125971794128, Loss_G: 2.0555500984191895\n",
      "Epoch [33/100], Step [600/600], Loss_D: 0.8546804189682007, Loss_G: 2.1065759658813477\n",
      "Epoch [34/100], Step [200/600], Loss_D: 0.6740058064460754, Loss_G: 3.1179988384246826\n",
      "Epoch [34/100], Step [400/600], Loss_D: 0.797072172164917, Loss_G: 2.0558102130889893\n",
      "Epoch [34/100], Step [600/600], Loss_D: 0.6847079992294312, Loss_G: 1.7117141485214233\n",
      "Epoch [35/100], Step [200/600], Loss_D: 0.6003972887992859, Loss_G: 2.387235641479492\n",
      "Epoch [35/100], Step [400/600], Loss_D: 0.7875756025314331, Loss_G: 2.226562261581421\n",
      "Epoch [35/100], Step [600/600], Loss_D: 0.7870197892189026, Loss_G: 2.2834906578063965\n",
      "Epoch [36/100], Step [200/600], Loss_D: 0.8827759027481079, Loss_G: 1.4239370822906494\n",
      "Epoch [36/100], Step [400/600], Loss_D: 0.6589105129241943, Loss_G: 2.409770965576172\n",
      "Epoch [36/100], Step [600/600], Loss_D: 0.8344776630401611, Loss_G: 1.8887563943862915\n",
      "Epoch [37/100], Step [200/600], Loss_D: 0.7701897025108337, Loss_G: 1.9818497896194458\n",
      "Epoch [37/100], Step [400/600], Loss_D: 0.6291868686676025, Loss_G: 1.880820870399475\n",
      "Epoch [37/100], Step [600/600], Loss_D: 0.784793496131897, Loss_G: 1.9860583543777466\n",
      "Epoch [38/100], Step [200/600], Loss_D: 0.8232500553131104, Loss_G: 1.7876321077346802\n",
      "Epoch [38/100], Step [400/600], Loss_D: 0.5773725509643555, Loss_G: 2.1495490074157715\n",
      "Epoch [38/100], Step [600/600], Loss_D: 0.9181151390075684, Loss_G: 1.9513933658599854\n",
      "Epoch [39/100], Step [200/600], Loss_D: 0.6463975310325623, Loss_G: 2.4457614421844482\n",
      "Epoch [39/100], Step [400/600], Loss_D: 0.6284536123275757, Loss_G: 2.003106117248535\n",
      "Epoch [39/100], Step [600/600], Loss_D: 0.7823972702026367, Loss_G: 2.54919171333313\n",
      "Epoch [40/100], Step [200/600], Loss_D: 0.7807662487030029, Loss_G: 1.7189823389053345\n",
      "Epoch [40/100], Step [400/600], Loss_D: 0.6394661664962769, Loss_G: 2.02194881439209\n",
      "Epoch [40/100], Step [600/600], Loss_D: 1.1296058893203735, Loss_G: 1.4415209293365479\n",
      "Epoch [41/100], Step [200/600], Loss_D: 0.8738417625427246, Loss_G: 1.5749683380126953\n",
      "Epoch [41/100], Step [400/600], Loss_D: 0.9223684072494507, Loss_G: 2.1638970375061035\n",
      "Epoch [41/100], Step [600/600], Loss_D: 0.914232611656189, Loss_G: 2.042254686355591\n",
      "Epoch [42/100], Step [200/600], Loss_D: 0.9595242142677307, Loss_G: 1.761759638786316\n",
      "Epoch [42/100], Step [400/600], Loss_D: 0.6225161552429199, Loss_G: 1.9389220476150513\n",
      "Epoch [42/100], Step [600/600], Loss_D: 0.8791930675506592, Loss_G: 1.7370991706848145\n",
      "Epoch [43/100], Step [200/600], Loss_D: 0.6676625609397888, Loss_G: 2.3744914531707764\n",
      "Epoch [43/100], Step [400/600], Loss_D: 1.0435872077941895, Loss_G: 2.033970832824707\n",
      "Epoch [43/100], Step [600/600], Loss_D: 0.7458915710449219, Loss_G: 1.8376214504241943\n",
      "Epoch [44/100], Step [200/600], Loss_D: 1.0367777347564697, Loss_G: 1.7043639421463013\n",
      "Epoch [44/100], Step [400/600], Loss_D: 0.7564752101898193, Loss_G: 1.85536789894104\n",
      "Epoch [44/100], Step [600/600], Loss_D: 0.7704646587371826, Loss_G: 1.7210947275161743\n",
      "Epoch [45/100], Step [200/600], Loss_D: 0.7797819375991821, Loss_G: 1.8969563245773315\n",
      "Epoch [45/100], Step [400/600], Loss_D: 0.8947446346282959, Loss_G: 1.7084693908691406\n",
      "Epoch [45/100], Step [600/600], Loss_D: 0.9082146883010864, Loss_G: 1.9557307958602905\n",
      "Epoch [46/100], Step [200/600], Loss_D: 0.8888815641403198, Loss_G: 1.8442696332931519\n",
      "Epoch [46/100], Step [400/600], Loss_D: 0.7015907764434814, Loss_G: 1.7254995107650757\n",
      "Epoch [46/100], Step [600/600], Loss_D: 0.8468029499053955, Loss_G: 1.3943819999694824\n",
      "Epoch [47/100], Step [200/600], Loss_D: 0.8626158237457275, Loss_G: 1.5052545070648193\n",
      "Epoch [47/100], Step [400/600], Loss_D: 0.8428296446800232, Loss_G: 1.4240244626998901\n",
      "Epoch [47/100], Step [600/600], Loss_D: 0.7364296913146973, Loss_G: 1.7712470293045044\n",
      "Epoch [48/100], Step [200/600], Loss_D: 0.8635748624801636, Loss_G: 1.61599600315094\n",
      "Epoch [48/100], Step [400/600], Loss_D: 0.9470680952072144, Loss_G: 1.3718311786651611\n",
      "Epoch [48/100], Step [600/600], Loss_D: 0.7992988228797913, Loss_G: 2.049525737762451\n",
      "Epoch [49/100], Step [200/600], Loss_D: 0.6918413043022156, Loss_G: 1.7348110675811768\n",
      "Epoch [49/100], Step [400/600], Loss_D: 0.797827959060669, Loss_G: 1.6261571645736694\n",
      "Epoch [49/100], Step [600/600], Loss_D: 0.7989921569824219, Loss_G: 1.5713104009628296\n",
      "Epoch [50/100], Step [200/600], Loss_D: 0.8479825258255005, Loss_G: 2.0955071449279785\n",
      "Epoch [50/100], Step [400/600], Loss_D: 0.8152548670768738, Loss_G: 1.6526294946670532\n",
      "Epoch [50/100], Step [600/600], Loss_D: 0.8178069591522217, Loss_G: 1.9165221452713013\n",
      "Epoch [51/100], Step [200/600], Loss_D: 0.8738669157028198, Loss_G: 1.658951997756958\n",
      "Epoch [51/100], Step [400/600], Loss_D: 0.9007887244224548, Loss_G: 1.9141159057617188\n",
      "Epoch [51/100], Step [600/600], Loss_D: 0.7914770841598511, Loss_G: 1.9795937538146973\n",
      "Epoch [52/100], Step [200/600], Loss_D: 0.8673653602600098, Loss_G: 1.6313650608062744\n",
      "Epoch [52/100], Step [400/600], Loss_D: 1.010947346687317, Loss_G: 1.7838622331619263\n",
      "Epoch [52/100], Step [600/600], Loss_D: 0.8958388566970825, Loss_G: 2.1748476028442383\n",
      "Epoch [53/100], Step [200/600], Loss_D: 0.7686140537261963, Loss_G: 1.7543880939483643\n",
      "Epoch [53/100], Step [400/600], Loss_D: 0.7698244452476501, Loss_G: 1.8797895908355713\n",
      "Epoch [53/100], Step [600/600], Loss_D: 0.8830181956291199, Loss_G: 1.700997233390808\n",
      "Epoch [54/100], Step [200/600], Loss_D: 1.0621931552886963, Loss_G: 1.5935320854187012\n",
      "Epoch [54/100], Step [400/600], Loss_D: 0.8852653503417969, Loss_G: 1.704323649406433\n",
      "Epoch [54/100], Step [600/600], Loss_D: 0.9863089919090271, Loss_G: 1.7576427459716797\n",
      "Epoch [55/100], Step [200/600], Loss_D: 0.7252011299133301, Loss_G: 1.981462001800537\n",
      "Epoch [55/100], Step [400/600], Loss_D: 0.995032012462616, Loss_G: 1.4478936195373535\n",
      "Epoch [55/100], Step [600/600], Loss_D: 1.0953850746154785, Loss_G: 2.0410945415496826\n",
      "Epoch [56/100], Step [200/600], Loss_D: 0.8264223337173462, Loss_G: 1.9437174797058105\n",
      "Epoch [56/100], Step [400/600], Loss_D: 0.8454756736755371, Loss_G: 1.4096728563308716\n",
      "Epoch [56/100], Step [600/600], Loss_D: 0.9774341583251953, Loss_G: 1.47897207736969\n",
      "Epoch [57/100], Step [200/600], Loss_D: 0.9882571697235107, Loss_G: 1.3083224296569824\n",
      "Epoch [57/100], Step [400/600], Loss_D: 1.045333743095398, Loss_G: 1.256011724472046\n",
      "Epoch [57/100], Step [600/600], Loss_D: 0.9790291786193848, Loss_G: 1.5914793014526367\n",
      "Epoch [58/100], Step [200/600], Loss_D: 0.9413248300552368, Loss_G: 1.8453515768051147\n",
      "Epoch [58/100], Step [400/600], Loss_D: 1.0664772987365723, Loss_G: 1.2409319877624512\n",
      "Epoch [58/100], Step [600/600], Loss_D: 0.8573542833328247, Loss_G: 1.5488766431808472\n",
      "Epoch [59/100], Step [200/600], Loss_D: 0.8108692765235901, Loss_G: 1.657926082611084\n",
      "Epoch [59/100], Step [400/600], Loss_D: 1.0417159795761108, Loss_G: 1.8039582967758179\n",
      "Epoch [59/100], Step [600/600], Loss_D: 1.0145846605300903, Loss_G: 1.7081218957901\n",
      "Epoch [60/100], Step [200/600], Loss_D: 0.9235323071479797, Loss_G: 1.6156224012374878\n",
      "Epoch [60/100], Step [400/600], Loss_D: 1.0521327257156372, Loss_G: 1.523469090461731\n",
      "Epoch [60/100], Step [600/600], Loss_D: 0.9438992738723755, Loss_G: 1.6373803615570068\n",
      "Epoch [61/100], Step [200/600], Loss_D: 0.7408938407897949, Loss_G: 1.8726122379302979\n",
      "Epoch [61/100], Step [400/600], Loss_D: 0.7665917873382568, Loss_G: 1.7758795022964478\n",
      "Epoch [61/100], Step [600/600], Loss_D: 0.8161797523498535, Loss_G: 1.611314058303833\n",
      "Epoch [62/100], Step [200/600], Loss_D: 1.0380173921585083, Loss_G: 1.465261697769165\n",
      "Epoch [62/100], Step [400/600], Loss_D: 0.797005832195282, Loss_G: 1.9494823217391968\n",
      "Epoch [62/100], Step [600/600], Loss_D: 0.9454696178436279, Loss_G: 1.5622985363006592\n",
      "Epoch [63/100], Step [200/600], Loss_D: 1.0672751665115356, Loss_G: 1.1266589164733887\n",
      "Epoch [63/100], Step [400/600], Loss_D: 0.8183826208114624, Loss_G: 1.8595620393753052\n",
      "Epoch [63/100], Step [600/600], Loss_D: 0.8591516613960266, Loss_G: 1.8637670278549194\n",
      "Epoch [64/100], Step [200/600], Loss_D: 0.9832661151885986, Loss_G: 1.8075519800186157\n",
      "Epoch [64/100], Step [400/600], Loss_D: 0.9092477560043335, Loss_G: 1.5513612031936646\n",
      "Epoch [64/100], Step [600/600], Loss_D: 1.0070407390594482, Loss_G: 1.4872112274169922\n",
      "Epoch [65/100], Step [200/600], Loss_D: 1.0388551950454712, Loss_G: 1.4472848176956177\n",
      "Epoch [65/100], Step [400/600], Loss_D: 0.9741955995559692, Loss_G: 1.6377825736999512\n",
      "Epoch [65/100], Step [600/600], Loss_D: 0.9609988927841187, Loss_G: 1.3621325492858887\n",
      "Epoch [66/100], Step [200/600], Loss_D: 0.7531872987747192, Loss_G: 1.6553126573562622\n",
      "Epoch [66/100], Step [400/600], Loss_D: 0.8344230651855469, Loss_G: 1.4678548574447632\n",
      "Epoch [66/100], Step [600/600], Loss_D: 0.9575726985931396, Loss_G: 1.2561219930648804\n",
      "Epoch [67/100], Step [200/600], Loss_D: 1.0033038854599, Loss_G: 1.4820632934570312\n",
      "Epoch [67/100], Step [400/600], Loss_D: 0.9985948801040649, Loss_G: 1.4378222227096558\n",
      "Epoch [67/100], Step [600/600], Loss_D: 0.7552916407585144, Loss_G: 1.755708932876587\n",
      "Epoch [68/100], Step [200/600], Loss_D: 1.0641698837280273, Loss_G: 1.4717456102371216\n",
      "Epoch [68/100], Step [400/600], Loss_D: 1.0748565196990967, Loss_G: 1.5611646175384521\n",
      "Epoch [68/100], Step [600/600], Loss_D: 0.7212346792221069, Loss_G: 1.7151620388031006\n",
      "Epoch [69/100], Step [200/600], Loss_D: 0.9400418996810913, Loss_G: 1.3847615718841553\n",
      "Epoch [69/100], Step [400/600], Loss_D: 1.148320198059082, Loss_G: 1.294913411140442\n",
      "Epoch [69/100], Step [600/600], Loss_D: 0.8219836950302124, Loss_G: 1.6221330165863037\n",
      "Epoch [70/100], Step [200/600], Loss_D: 0.9211734533309937, Loss_G: 1.3710383176803589\n",
      "Epoch [70/100], Step [400/600], Loss_D: 0.9737361669540405, Loss_G: 1.5933605432510376\n",
      "Epoch [70/100], Step [600/600], Loss_D: 0.9281871914863586, Loss_G: 1.749257206916809\n",
      "Epoch [71/100], Step [200/600], Loss_D: 1.0755473375320435, Loss_G: 1.321454405784607\n",
      "Epoch [71/100], Step [400/600], Loss_D: 0.8980002403259277, Loss_G: 1.805724859237671\n",
      "Epoch [71/100], Step [600/600], Loss_D: 0.923126220703125, Loss_G: 1.5556800365447998\n",
      "Epoch [72/100], Step [200/600], Loss_D: 1.0684144496917725, Loss_G: 1.321668028831482\n",
      "Epoch [72/100], Step [400/600], Loss_D: 0.8245685696601868, Loss_G: 1.7595996856689453\n",
      "Epoch [72/100], Step [600/600], Loss_D: 1.0326719284057617, Loss_G: 1.6831759214401245\n",
      "Epoch [73/100], Step [200/600], Loss_D: 0.8109123110771179, Loss_G: 1.952012538909912\n",
      "Epoch [73/100], Step [400/600], Loss_D: 1.1187951564788818, Loss_G: 1.2836486101150513\n",
      "Epoch [73/100], Step [600/600], Loss_D: 1.0640939474105835, Loss_G: 1.581148624420166\n",
      "Epoch [74/100], Step [200/600], Loss_D: 0.9683926701545715, Loss_G: 1.6228359937667847\n",
      "Epoch [74/100], Step [400/600], Loss_D: 0.9223501682281494, Loss_G: 1.4414435625076294\n",
      "Epoch [74/100], Step [600/600], Loss_D: 0.9021871089935303, Loss_G: 1.8167041540145874\n",
      "Epoch [75/100], Step [200/600], Loss_D: 1.0096688270568848, Loss_G: 1.521989107131958\n",
      "Epoch [75/100], Step [400/600], Loss_D: 0.9580591917037964, Loss_G: 1.6023107767105103\n",
      "Epoch [75/100], Step [600/600], Loss_D: 0.9330263137817383, Loss_G: 1.6129209995269775\n",
      "Epoch [76/100], Step [200/600], Loss_D: 0.8540457487106323, Loss_G: 1.7517220973968506\n",
      "Epoch [76/100], Step [400/600], Loss_D: 1.0411583185195923, Loss_G: 1.5394428968429565\n",
      "Epoch [76/100], Step [600/600], Loss_D: 1.0752019882202148, Loss_G: 1.4331769943237305\n",
      "Epoch [77/100], Step [200/600], Loss_D: 1.0038037300109863, Loss_G: 1.4376522302627563\n",
      "Epoch [77/100], Step [400/600], Loss_D: 1.0202349424362183, Loss_G: 1.3970750570297241\n",
      "Epoch [77/100], Step [600/600], Loss_D: 0.9382632970809937, Loss_G: 1.5082110166549683\n",
      "Epoch [78/100], Step [200/600], Loss_D: 0.8275185823440552, Loss_G: 1.9083471298217773\n",
      "Epoch [78/100], Step [400/600], Loss_D: 1.0031991004943848, Loss_G: 1.5727460384368896\n",
      "Epoch [78/100], Step [600/600], Loss_D: 1.0944361686706543, Loss_G: 1.4177428483963013\n",
      "Epoch [79/100], Step [200/600], Loss_D: 1.0879026651382446, Loss_G: 1.5912832021713257\n",
      "Epoch [79/100], Step [400/600], Loss_D: 0.9674350023269653, Loss_G: 1.3763542175292969\n",
      "Epoch [79/100], Step [600/600], Loss_D: 1.0328116416931152, Loss_G: 1.4001623392105103\n",
      "Epoch [80/100], Step [200/600], Loss_D: 0.8849227428436279, Loss_G: 1.8857522010803223\n",
      "Epoch [80/100], Step [400/600], Loss_D: 1.043258547782898, Loss_G: 1.7075799703598022\n",
      "Epoch [80/100], Step [600/600], Loss_D: 1.093754768371582, Loss_G: 1.5330299139022827\n",
      "Epoch [81/100], Step [200/600], Loss_D: 1.0245983600616455, Loss_G: 1.3170580863952637\n",
      "Epoch [81/100], Step [400/600], Loss_D: 1.0335619449615479, Loss_G: 1.3413947820663452\n",
      "Epoch [81/100], Step [600/600], Loss_D: 0.8699296116828918, Loss_G: 1.4874978065490723\n",
      "Epoch [82/100], Step [200/600], Loss_D: 0.8972732424736023, Loss_G: 1.370820164680481\n",
      "Epoch [82/100], Step [400/600], Loss_D: 1.0073819160461426, Loss_G: 1.28337562084198\n",
      "Epoch [82/100], Step [600/600], Loss_D: 0.9026377201080322, Loss_G: 1.3387529850006104\n",
      "Epoch [83/100], Step [200/600], Loss_D: 0.9210691452026367, Loss_G: 1.4842147827148438\n",
      "Epoch [83/100], Step [400/600], Loss_D: 0.9997991323471069, Loss_G: 1.5616637468338013\n",
      "Epoch [83/100], Step [600/600], Loss_D: 1.0415879487991333, Loss_G: 1.6025017499923706\n",
      "Epoch [84/100], Step [200/600], Loss_D: 0.9033160209655762, Loss_G: 1.5689349174499512\n",
      "Epoch [84/100], Step [400/600], Loss_D: 0.9394073486328125, Loss_G: 1.6115736961364746\n",
      "Epoch [84/100], Step [600/600], Loss_D: 1.0313827991485596, Loss_G: 1.318457007408142\n",
      "Epoch [85/100], Step [200/600], Loss_D: 0.9305250644683838, Loss_G: 1.492837905883789\n",
      "Epoch [85/100], Step [400/600], Loss_D: 1.1559112071990967, Loss_G: 1.363206148147583\n",
      "Epoch [85/100], Step [600/600], Loss_D: 0.997620701789856, Loss_G: 1.74607515335083\n",
      "Epoch [86/100], Step [200/600], Loss_D: 1.0212199687957764, Loss_G: 1.6389756202697754\n",
      "Epoch [86/100], Step [400/600], Loss_D: 0.9280875325202942, Loss_G: 1.3447613716125488\n",
      "Epoch [86/100], Step [600/600], Loss_D: 0.9230434894561768, Loss_G: 1.3110135793685913\n",
      "Epoch [87/100], Step [200/600], Loss_D: 1.0771877765655518, Loss_G: 1.255689024925232\n",
      "Epoch [87/100], Step [400/600], Loss_D: 1.0394721031188965, Loss_G: 1.3171539306640625\n",
      "Epoch [87/100], Step [600/600], Loss_D: 0.9214993119239807, Loss_G: 1.6359292268753052\n",
      "Epoch [88/100], Step [200/600], Loss_D: 0.860794723033905, Loss_G: 1.68194580078125\n",
      "Epoch [88/100], Step [400/600], Loss_D: 1.0216064453125, Loss_G: 1.457192063331604\n",
      "Epoch [88/100], Step [600/600], Loss_D: 1.05018150806427, Loss_G: 1.142823338508606\n",
      "Epoch [89/100], Step [200/600], Loss_D: 0.9853562116622925, Loss_G: 1.5495656728744507\n",
      "Epoch [89/100], Step [400/600], Loss_D: 0.921107292175293, Loss_G: 1.3696972131729126\n",
      "Epoch [89/100], Step [600/600], Loss_D: 1.0026684999465942, Loss_G: 1.560671091079712\n",
      "Epoch [90/100], Step [200/600], Loss_D: 0.9314583539962769, Loss_G: 1.59138822555542\n",
      "Epoch [90/100], Step [400/600], Loss_D: 0.9273179769515991, Loss_G: 1.6834064722061157\n",
      "Epoch [90/100], Step [600/600], Loss_D: 1.0668530464172363, Loss_G: 1.3491119146347046\n",
      "Epoch [91/100], Step [200/600], Loss_D: 0.9149119853973389, Loss_G: 1.5160174369812012\n",
      "Epoch [91/100], Step [400/600], Loss_D: 0.9336792230606079, Loss_G: 1.6011911630630493\n",
      "Epoch [91/100], Step [600/600], Loss_D: 0.900621771812439, Loss_G: 1.5253902673721313\n",
      "Epoch [92/100], Step [200/600], Loss_D: 1.08829665184021, Loss_G: 1.6341866254806519\n",
      "Epoch [92/100], Step [400/600], Loss_D: 1.072026252746582, Loss_G: 1.5289355516433716\n",
      "Epoch [92/100], Step [600/600], Loss_D: 1.1033241748809814, Loss_G: 1.1898032426834106\n",
      "Epoch [93/100], Step [200/600], Loss_D: 1.091458797454834, Loss_G: 1.2036045789718628\n",
      "Epoch [93/100], Step [400/600], Loss_D: 0.987208366394043, Loss_G: 1.6557738780975342\n",
      "Epoch [93/100], Step [600/600], Loss_D: 1.023750901222229, Loss_G: 1.4905577898025513\n",
      "Epoch [94/100], Step [200/600], Loss_D: 0.9953374862670898, Loss_G: 1.4565060138702393\n",
      "Epoch [94/100], Step [400/600], Loss_D: 0.9731521606445312, Loss_G: 1.470566987991333\n",
      "Epoch [94/100], Step [600/600], Loss_D: 0.8455424308776855, Loss_G: 1.5281802415847778\n",
      "Epoch [95/100], Step [200/600], Loss_D: 0.9618034362792969, Loss_G: 1.2701348066329956\n",
      "Epoch [95/100], Step [400/600], Loss_D: 1.0418896675109863, Loss_G: 1.5727746486663818\n",
      "Epoch [95/100], Step [600/600], Loss_D: 1.1249208450317383, Loss_G: 1.1653496026992798\n",
      "Epoch [96/100], Step [200/600], Loss_D: 1.038705587387085, Loss_G: 1.5553103685379028\n",
      "Epoch [96/100], Step [400/600], Loss_D: 0.8319476842880249, Loss_G: 1.780245304107666\n",
      "Epoch [96/100], Step [600/600], Loss_D: 1.109230399131775, Loss_G: 1.4829555749893188\n",
      "Epoch [97/100], Step [200/600], Loss_D: 1.1367989778518677, Loss_G: 1.4736851453781128\n",
      "Epoch [97/100], Step [400/600], Loss_D: 1.0173579454421997, Loss_G: 1.2018429040908813\n",
      "Epoch [97/100], Step [600/600], Loss_D: 1.0785053968429565, Loss_G: 1.501977562904358\n",
      "Epoch [98/100], Step [200/600], Loss_D: 0.9686883091926575, Loss_G: 1.2837083339691162\n",
      "Epoch [98/100], Step [400/600], Loss_D: 1.1416436433792114, Loss_G: 1.598293423652649\n",
      "Epoch [98/100], Step [600/600], Loss_D: 0.9765784740447998, Loss_G: 1.7124062776565552\n",
      "Epoch [99/100], Step [200/600], Loss_D: 0.995572030544281, Loss_G: 1.4844387769699097\n",
      "Epoch [99/100], Step [400/600], Loss_D: 0.9073362350463867, Loss_G: 1.1930328607559204\n",
      "Epoch [99/100], Step [600/600], Loss_D: 1.0624682903289795, Loss_G: 1.1695042848587036\n",
      "Epoch [100/100], Step [200/600], Loss_D: 1.028968334197998, Loss_G: 1.2648351192474365\n",
      "Epoch [100/100], Step [400/600], Loss_D: 1.0963157415390015, Loss_G: 1.6186506748199463\n",
      "Epoch [100/100], Step [600/600], Loss_D: 1.0320236682891846, Loss_G: 1.3018102645874023\n",
      "Total Training Time: 1845.97s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ImageGenerator(nn.Module):\n",
    "    \"\"\"Generates images from a given noise vector.\"\"\"\n",
    "    def __init__(self, noise_dim, image_dim):\n",
    "        super(ImageGenerator, self).__init__()\n",
    "        self.first_layer = nn.Sequential(nn.Linear(noise_dim, 256), nn.LeakyReLU(0.2))\n",
    "        self.second_layer = nn.Sequential(nn.Linear(256, 512), nn.LeakyReLU(0.2))\n",
    "        self.third_layer = nn.Sequential(nn.Linear(512, 1024), nn.LeakyReLU(0.2))\n",
    "        self.final_layer = nn.Sequential(nn.Linear(1024, image_dim), nn.Tanh())\n",
    "\n",
    "    def forward(self, noise):\n",
    "        noise = self.first_layer(noise)\n",
    "        noise = self.second_layer(noise)\n",
    "        noise = self.third_layer(noise)\n",
    "        return self.final_layer(noise)\n",
    "\n",
    "\n",
    "class ImageDiscriminator(nn.Module):\n",
    "    \"\"\"Predicts whether an image is real or generated.\"\"\"\n",
    "    def __init__(self, image_dim, output_dim=1):\n",
    "        super(ImageDiscriminator, self).__init__()\n",
    "        self.first_layer = nn.Sequential(nn.Linear(image_dim, 1024), nn.LeakyReLU(0.2))\n",
    "        self.second_layer = nn.Sequential(nn.Linear(1024, 512), nn.LeakyReLU(0.2))\n",
    "        self.third_layer = nn.Sequential(nn.Linear(512, 256), nn.LeakyReLU(0.2))\n",
    "        self.final_layer = nn.Sequential(nn.Linear(256, output_dim), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = self.first_layer(image)\n",
    "        image = self.second_layer(image)\n",
    "        image = self.third_layer(image)\n",
    "        return self.final_layer(image)\n",
    "\n",
    "\n",
    "def display_images(generator, noise, epoch, show=False, save=False, path='result.png'):\n",
    "    with torch.no_grad():\n",
    "        images = generator(noise).cpu().view(-1, 28, 28)\n",
    "        fig, axes = plt.subplots(5, 5, figsize=(5, 5), sharex=True, sharey=True)\n",
    "        for ax, img in zip(axes.flatten(), images):\n",
    "            ax.xaxis.set_visible(False)\n",
    "            ax.yaxis.set_visible(False)\n",
    "            ax.imshow(img.detach().numpy(), cmap='gray_r')\n",
    "    fig.suptitle(f'Epoch {epoch}')\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_loss_history(history, show=False, save=False, path='loss_history.png'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['discriminator_losses'], label='Discriminator Loss')\n",
    "    plt.plot(history['generator_losses'], label='Generator Loss')\n",
    "    plt.title(\"Training Losses\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def generate_noise(batch_size, dimensions):\n",
    "    return torch.randn(batch_size, dimensions)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    data_directory = './MNIST_data/'\n",
    "    results_directory = './MNIST_GAN_results/'\n",
    "    image_results_directory = './MNIST_GAN_results/images'\n",
    "\n",
    "    if not os.path.exists(results_directory):\n",
    "        os.makedirs(results_directory)\n",
    "    if not os.path.exists(image_results_directory):\n",
    "        os.makedirs(image_results_directory)\n",
    "\n",
    "    batch_size = 100\n",
    "    learning_rate = 0.0002\n",
    "    training_epochs = 100\n",
    "\n",
    "    noise_dimensions = 100\n",
    "    flat_image_dimensions = 28 * 28\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.MNIST(root=data_directory, train=True, download=True, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    generator = ImageGenerator(noise_dimensions, flat_image_dimensions).to(device)\n",
    "    discriminator = ImageDiscriminator(flat_image_dimensions).to(device)\n",
    "\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    history = {'discriminator_losses': [], 'generator_losses': []}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        for i, (images, _) in enumerate(loader):\n",
    "            images = images.view(batch_size, -1).to(device)\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Real images\n",
    "            outputs_real = discriminator(images)\n",
    "            loss_real = loss_fn(outputs_real, real_labels)\n",
    "\n",
    "            # Fake images\n",
    "            noise = generate_noise(batch_size, noise_dimensions).to(device)\n",
    "            fake_images = generator(noise)\n",
    "            outputs_fake = discriminator(fake_images.detach())\n",
    "            loss_fake = loss_fn(outputs_fake, fake_labels)\n",
    "\n",
    "            # Backprop and optimize\n",
    "            loss_D = loss_real + loss_fake\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            outputs_fake = discriminator(fake_images)\n",
    "            loss_G = loss_fn(outputs_fake, real_labels)\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            if (i + 1) % 200 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{training_epochs}], Step [{i + 1}/{len(loader)}], Loss_D: {loss_D.item()}, Loss_G: {loss_G.item()}')\n",
    "\n",
    "        history['discriminator_losses'].append(loss_D.item())\n",
    "        history['generator_losses'].append(loss_G.item())\n",
    "\n",
    "        # Display images periodically\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            display_images(generator, generate_noise(25, noise_dimensions).to(device), epoch + 1, save=True, path=f'{image_results_directory}/Epoch_{epoch + 1}.png')\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f'Total Training Time: {total_time:.2f}s')\n",
    "\n",
    "    # Save the model checkpoints\n",
    "    torch.save(generator.state_dict(), f'{results_directory}/generator.pth')\n",
    "    torch.save(discriminator.state_dict(), f'{results_directory}/discriminator.pth')\n",
    "\n",
    "    # Plot and save loss history\n",
    "    plot_loss_history(history, save=True, path=f'{results_directory}/loss_history.png')\n",
    "\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
